{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>depression hurts, cymbalta can help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@jessicama20045 right, but cipro can make thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@fibby1123 are you on paxil .. i need help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>@redicine the lamotrigine and sjs just made ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>have decided to skip my #humira shot today. my...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                              tweet\n",
       "0      0                depression hurts, cymbalta can help\n",
       "1      0  @jessicama20045 right, but cipro can make thin...\n",
       "2      0         @fibby1123 are you on paxil .. i need help\n",
       "3      0  @redicine the lamotrigine and sjs just made ch...\n",
       "4      0  have decided to skip my #humira shot today. my..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data into Pandas dataframe\n",
    "df = pd.read_csv('task2_en_training.tsv', sep='\\t')[['class', 'tweet']]\n",
    "df['class'] = df['class'].apply(lambda x: int(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6794</td>\n",
       "      <td>0</td>\n",
       "      <td>@awtracing @jimasmith12 am still waiting 4 tys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11043</td>\n",
       "      <td>0</td>\n",
       "      <td>@washingtonpost simple answer. doctors not wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6623</td>\n",
       "      <td>0</td>\n",
       "      <td>@luxepain do you have thalidomide arms?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4646</td>\n",
       "      <td>0</td>\n",
       "      <td>@amyellen_xo fluoxetine is a common one, but i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5086</td>\n",
       "      <td>0</td>\n",
       "      <td>#tweetyourweakness nicotine and caffine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                              tweet\n",
       "6794       0  @awtracing @jimasmith12 am still waiting 4 tys...\n",
       "11043      0  @washingtonpost simple answer. doctors not wan...\n",
       "6623       0            @luxepain do you have thalidomide arms?\n",
       "4646       0  @amyellen_xo fluoxetine is a common one, but i...\n",
       "5086       0            #tweetyourweakness nicotine and caffine"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[np.random.permutation(len(df))]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(scipy.sparse.csr.csr_matrix, pandas.core.series.Series)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['tweet']\n",
    "Y = df['class']\n",
    "\n",
    "feature_extraction = TfidfVectorizer()\n",
    "X = feature_extraction.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y , test_size=0.2)\n",
    "type(X_train), type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class sklearn.svm.SVC(C=1.0, \n",
    "#                       kernel='rbf', \n",
    "#                       degree=3, \n",
    "#                       gamma='scale', \n",
    "#                       coef0=0.0, \n",
    "#                       shrinking=True, \n",
    "#                       probability=False, \n",
    "#                       tol=0.001, \n",
    "#                       cache_size=200, \n",
    "#                       class_weight=None, \n",
    "#                       verbose=False, \n",
    "#                       max_iter=-1, \n",
    "#                       decision_function_shape='ovr', \n",
    "#                       break_ties=False, \n",
    "#                       random_state=None)[source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = SVC(kernel='linear')\n",
    "SVM.fit(X_train,y_train)\n",
    "\n",
    "predictions_SVM = SVM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  91.38476514967145\n",
      "SVM F1 Score ->  31.92307692307692\n",
      "SVM Roc_auc Score ->  85.74654278305964\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Accuracy Score -> \", accuracy_score(predictions_SVM, y_test)*100)\n",
    "print(\"SVM F1 Score -> \", f1_score(predictions_SVM, y_test)*100)\n",
    "print(\"SVM Roc_auc Score -> \", roc_auc_score(predictions_SVM, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHUFFLE SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10982</td>\n",
       "      <td>0</td>\n",
       "      <td>everything can be fixed, antara nak atau tak n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19974</td>\n",
       "      <td>0</td>\n",
       "      <td>oh and dexilant helps with heartburn and indig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>i still have a decent amount of seroquel, reme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9395</td>\n",
       "      <td>0</td>\n",
       "      <td>delhi hc: merck - glenmark januvia patent case...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20332</td>\n",
       "      <td>0</td>\n",
       "      <td>took an oxycodone and i'm still in pain.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                              tweet\n",
       "10982      0  everything can be fixed, antara nak atau tak n...\n",
       "19974      0  oh and dexilant helps with heartburn and indig...\n",
       "88         0  i still have a decent amount of seroquel, reme...\n",
       "9395       0  delhi hc: merck - glenmark januvia patent case...\n",
       "20332      0           took an oxycodone and i'm still in pain."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "data = df\n",
    "data = data.iloc[np.random.permutation(len(df))]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 6\n",
    "samp = len(data)//6\n",
    "\n",
    "training_data = data[:samp]\n",
    "control_data = data[samp:]\n",
    "\n",
    "#training_data, control_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Проблема с конкатенацией массивов...***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'florida is in need of cymbalta! all this depression and shit!'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2dc9a4c8f980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mSVM2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mSVM2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mpredictions_SVM2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVM2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    144\u001b[0m         X, y = check_X_y(X, y, dtype=np.float64,\n\u001b[1;32m    145\u001b[0m                          \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                          accept_large_sparse=False)\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    720\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'florida is in need of cymbalta! all this depression and shit!'"
     ]
    }
   ],
   "source": [
    "split = ShuffleSplit(n_splits=5, test_size=1/4, random_state=5)\n",
    "\n",
    "for fold in range(k):\n",
    "    print(fold+1)\n",
    "\n",
    "    #X_train = np.append(X.toarray()[:samp*fold], X.toarray()[samp*(fold+1):])\n",
    "    X_train = np.append(data['tweet'][:samp*fold], data['tweet'][samp*(fold+1):])\n",
    "    X_test = X[samp*fold:samp*(fold+1)]\n",
    "    #y_train = np.append(np.array(Y[:samp*fold]), np.array(Y[samp*(fold+1):]))\n",
    "    y_train = np.append(data['tweet'][:samp*fold], data['tweet'][samp*(fold+1):])\n",
    "    y_test = Y[samp*fold:samp*(fold+1)]\n",
    "    \n",
    "    SVM2 = SVC(kernel='linear')\n",
    "    SVM2.fit(X_train, y_train)\n",
    "    \n",
    "    predictions_SVM2 = SVM2.predict(X_test)\n",
    "    \n",
    "    f1.append(f1_score(predictions_SVM2, y_test)*100)\n",
    "    print(\"SVM Accuracy Score -> \", accuracy_score(predictions_SVM2, y_test)*100)\n",
    "    print(\"SVM F1 Score -> \", f1[-1])\n",
    "    print(\"SVM Roc_auc Score -> \", roc_auc_score(predictions_SVM2, y_test)*100)\n",
    "    \n",
    "predictions_SVM = SVM2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
