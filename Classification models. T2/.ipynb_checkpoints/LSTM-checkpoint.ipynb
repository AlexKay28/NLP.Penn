{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#visualisation and work with dfs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding,  Bidirectional, TimeDistributed, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data into Pandas dataframe\n",
    "df = pd.read_csv('task2_en_training.tsv', sep='\\t')[['class', 'tweet']]\n",
    "df['class'] = df['class'].apply(lambda x: int(x))\n",
    "#df, df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Number of labeled messages')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Understand the distribution better.\n",
    "# 0 meand NO ADR, 1 ADR exists\n",
    "sns.countplot(df['class'])\n",
    "plt.xlabel('Label')\n",
    "plt.title('Number of labeled messages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create input and output vectors just by splitting them on 2! \n",
    "X = df['tweet']\n",
    "Y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17462,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split into training and test data.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train,'   =======================     ==============================    ' ,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data\n",
    "#   Tokenize the data and convert the text to sequences.\n",
    "#   Add padding to ensure that all the sequences have the same shape.\n",
    "#   There are many ways of taking the max_len and here an arbitrary length of 150 is chosen.\n",
    "max_words = 1000\n",
    "max_len = 150\n",
    "tok = Tokenizer(num_words=max_words) #just tokenization... probably like BOF\n",
    "tok.fit_on_texts(X_train)\n",
    "sequences = tok.texts_to_sequences(X_train) # got the arr of sequences which appear like array of array_of_tokens\n",
    "\n",
    "sequences_matrix = sequence.pad_sequences(sequences, maxlen=max_len) #pads sequences.. makes it softly? \n",
    "# https://keras.io/preprocessing/sequence/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'the', 'to', 'a', 'and', 'for', 'of', 'is', 'in', 'my', 'on', 'it', 'you', 'me', 'that', 'with', 'have', 'but', 'not'] []\n"
     ]
    }
   ],
   "source": [
    "print([tok.index_word[i] for i in range(1,20)], [tok.index_word[i] for i in range(-1,-20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 150, 50)           50000     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "Activation_layer (Activation (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 96,337\n",
      "Trainable params: 96,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Define the RNN structure\n",
    "def RNN():\n",
    "    inputs = Input(name='inputs', shape=[max_len])\n",
    "    layer = Embedding(max_words, 50, input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256, name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1, name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid', name='Activation_layer')(layer) #WAS CHANGED ..\n",
    "    #layer = Activation('softmax')(layer)\n",
    "    model = Model(inputs=inputs, outputs=layer)\n",
    "    return model\n",
    "\n",
    "# Call the function and compile the model\n",
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(), metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath=\"weights.{epoch:02d}-{val_loss:.2f}.txt\"\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "#callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexkay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13969 samples, validate on 3493 samples\n",
      "Epoch 1/10\n",
      "13969/13969 [==============================] - 13s 929us/step - loss: 0.3031 - acc: 0.9039 - val_loss: 0.2672 - val_acc: 0.9138\n",
      "Epoch 2/10\n",
      "13969/13969 [==============================] - 12s 881us/step - loss: 0.2296 - acc: 0.9140 - val_loss: 0.2192 - val_acc: 0.9224\n",
      "Epoch 3/10\n",
      "13969/13969 [==============================] - 12s 859us/step - loss: 0.2131 - acc: 0.9185 - val_loss: 0.2269 - val_acc: 0.9224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f473ddedc50>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on the training data\n",
    "model.fit(sequences_matrix,\n",
    "          Y_train,\n",
    "          #validation_data=(Y_test),\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          validation_split=0.2,\n",
    "          #callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n",
    "          callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001), \n",
    "                     ModelCheckpoint(filepath, monitor='val_loss', save_weights_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname = \"weights.01-0.27.txt\"\n",
    "# model.load_weights(fname)\n",
    "# model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09863724853990914"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i, j in zip(model.predict(test_sequences_matrix), Y_test):\n",
    "#     print(i, j)\n",
    "list(model.predict(test_sequences_matrix))\n",
    "predicts = [i[0] for i in model.predict(test_sequences_matrix)]\n",
    "\n",
    "gap = (max(predicts)-min(predicts))/2\n",
    "for i in range(len(predicts)):\n",
    "    if i <= gap: predicts[i] = 0\n",
    "    else: predicts[i] = 1\n",
    "f1_score(Y_test, predicts, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the test set data\n",
    "test_sequences = tok.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3082/3082 [==============================] - 1s 336us/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "accr = model.evaluate(test_sequences_matrix, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set\n",
      "  Loss: 0.259\n",
      "  Accuracy: 0.910\n"
     ]
    }
   ],
   "source": [
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN2 , just playing with layers and features..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the RNN2 structure BI-LSTM\n",
    "def RNN2():\n",
    "    inputs = Input(name='inputs', shape=[max_len])\n",
    "    layer = Embedding(max_words, 50, input_length=max_len)(inputs)\n",
    "    layer = Bidirectional(LSTM(100, return_sequences=True, dropout=0.50), merge_mode='concat')(layer)\n",
    "    layer = TimeDistributed(Dense(100, activation='relu'))(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(100, activation='relu')(layer)\n",
    "    layer = Dense(1, activation='softmax')(layer)\n",
    "    model = Model(inputs=inputs, outputs=layer)\n",
    "    \n",
    "    MLP = Sequential()\n",
    "    MLP.add(Dense(512, input_shape=(3073, ), activation='relu'))\n",
    "    MLP.add(Dropout(0.5))\n",
    "    MLP.add(Dense(Y_train.shape[1], activation='softmax'))\n",
    "    MLP = Model(inputs=inputs,)\n",
    "    return MLP\n",
    "\n",
    "MLP.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "MLP.summary()\n",
    "#model.summary()\n",
    "#model.compile(loss='sparse_categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "#return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = RNN2()\n",
    "model2.summary()\n",
    "model2.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on the training data\n",
    "model2.fit(sequences_matrix, \n",
    "           Y_train, \n",
    "           batch_size=128,\n",
    "           epochs=10,\n",
    "           validation_split=0.2, \n",
    "           callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n",
    "\n",
    "#model.fit(X_train,Y_train,validation_split=0.25, nb_epoch = 10, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
